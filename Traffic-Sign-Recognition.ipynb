{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oACH_kr8Vbxk",
        "outputId": "4945dc20-7fa3-49b7-f0ce-049662bf9dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade torch torchvision torchaudio\n",
        "!pip -q install scikit-learn tqdm gradio opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports, config, helpers"
      ],
      "metadata": {
        "id": "FU83IUhRVwZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Imports, config, helpers (with stronger aug)\n",
        "import os, json, random, time\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Repro\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return transforms.Compose([\n",
        "            # Stronger, more realistic augmentation for street photos\n",
        "            transforms.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0)),\n",
        "            transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
        "            transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)], p=0.3),\n",
        "            transforms.RandomAffine(degrees=12, translate=(0.08, 0.08), scale=(0.9, 1.1)),\n",
        "            transforms.RandomHorizontalFlip(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomErasing(p=0.25, scale=(0.02, 0.08), value='random'),\n",
        "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "        ])\n",
        "\n",
        "def build_model(num_classes: int, pretrained=True):\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def save_label_map(class_to_idx: dict, path=\"label_map.json\"):\n",
        "    idx_to_class = {int(v): k for k, v in class_to_idx.items()}\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(idx_to_class, f, indent=2)\n",
        "\n",
        "def load_label_map(path=\"label_map.json\"):\n",
        "    with open(path, \"r\") as f:\n",
        "        d = json.load(f)\n",
        "    return {int(k): v for k, v in d.items()}\n",
        "\n",
        "def topk_probs(logits, k=5):\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    top_p, top_i = probs.topk(k)\n",
        "    return top_p.detach().cpu().numpy().tolist(), top_i.detach().cpu().numpy().tolist()\n",
        "\n",
        "print(\"Device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OyFdjn5Vwye",
        "outputId": "e60a661e-07aa-49e2-dcaa-bb77baf725db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "UKcdtuvFV15q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "DATA_ROOT = \"./data\"\n",
        "VAL_SPLIT = 0.15\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_full = datasets.GTSRB(\n",
        "    root=DATA_ROOT, split=\"train\", download=True, transform=get_transforms(train=True)\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Some versions expose .classes / .class_to_idx\n",
        "    class_names = list(train_full.classes)\n",
        "    class_to_idx = dict(train_full.class_to_idx)\n",
        "except Exception:\n",
        "    # Fallback: derive from targets; make readable names like \"class_0\"... \"class_42\"\n",
        "    class_ids = sorted({train_full[i][1] for i in range(len(train_full))})\n",
        "    class_names = [f\"class_{i}\" for i in class_ids]\n",
        "    class_to_idx = {name: idx for name, idx in zip(class_names, class_ids)}\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", num_classes)\n",
        "\n",
        "# Save label map for later inference/Gradio\n",
        "save_label_map(class_to_idx, \"label_map.json\")\n",
        "\n",
        "# Train/val split\n",
        "n_total = len(train_full)\n",
        "n_val = int(n_total * VAL_SPLIT)\n",
        "n_train = n_total - n_val\n",
        "train_set, val_set = random_split(\n",
        "    train_full, [n_train, n_val], generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "# Use eval transforms for val set\n",
        "val_set.dataset.transform = get_transforms(train=False)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "len(train_set), len(val_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CInIgHgoV2YX",
        "outputId": "7b9020f5-43e6-4370-ecf4-ae86f08dff78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 187M/187M [00:00<00:00, 223MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: 43\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22644, 3996)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 — Train (AMP + cosine LR + label smoothing)\n",
        "EPOCHS = 20               # a bit longer for stronger aug\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "BEST_WEIGHTS = \"model.pth\"\n",
        "\n",
        "model = build_model(num_classes=num_classes, pretrained=True).to(DEVICE)\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "# Label smoothing to reduce overconfidence, help generalization\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "def accuracy(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [train]\")\n",
        "    run_loss = 0.0; run_acc = 0.0; n = 0\n",
        "\n",
        "    for x, y in pbar:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        bs = y.size(0)\n",
        "        run_loss += loss.item() * bs\n",
        "        run_acc  += (logits.argmax(1) == y).float().sum().item()\n",
        "        n += bs\n",
        "        pbar.set_postfix(loss=run_loss/n, acc=run_acc/n)\n",
        "\n",
        "    # ---- Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0; val_acc = 0.0; m = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} [val]\"):\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            bs = y.size(0)\n",
        "            val_loss += loss.item() * bs\n",
        "            val_acc  += (logits.argmax(1) == y).float().sum().item()\n",
        "            m += bs\n",
        "    val_loss /= max(1, m)\n",
        "    val_acc  /= max(1, m)\n",
        "\n",
        "    print(f\"[E{epoch}] train_loss={run_loss/n:.4f} train_acc={run_acc/n:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_WEIGHTS)\n",
        "        print(f\"✅ Saved best to {BEST_WEIGHTS} (val_acc={best_val_acc:.4f})\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Training complete. Best val_acc:\", round(best_val_acc, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIHeGsSCV-UI",
        "outputId": "d114e928-5ea7-489b-d262-8b0c590a55d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 158MB/s]\n",
            "/tmp/ipython-input-2023327034.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
            "Epoch 1/20 [train]:   0%|          | 0/354 [00:00<?, ?it/s]/tmp/ipython-input-2023327034.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            "Epoch 1/20 [train]: 100%|██████████| 354/354 [00:58<00:00,  6.09it/s, acc=0.955, loss=0.867]\n",
            "Epoch 1/20 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E1] train_loss=0.8671 train_acc=0.9551 | val_loss=0.7079 val_acc=0.9982\n",
            "✅ Saved best to model.pth (val_acc=0.9982)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.34it/s, acc=1, loss=0.699]\n",
            "Epoch 2/20 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E2] train_loss=0.6995 train_acc=0.9995 | val_loss=0.6931 val_acc=1.0000\n",
            "✅ Saved best to model.pth (val_acc=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.52it/s, acc=1, loss=0.691]\n",
            "Epoch 3/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E3] train_loss=0.6910 train_acc=1.0000 | val_loss=0.6892 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.45it/s, acc=1, loss=0.689]\n",
            "Epoch 4/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E4] train_loss=0.6889 train_acc=1.0000 | val_loss=0.6878 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.38it/s, acc=0.999, loss=0.692]\n",
            "Epoch 5/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E5] train_loss=0.6922 train_acc=0.9992 | val_loss=0.7602 val_acc=0.9837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20 [train]: 100%|██████████| 354/354 [00:57<00:00,  6.11it/s, acc=0.998, loss=0.702]\n",
            "Epoch 6/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E6] train_loss=0.7024 train_acc=0.9979 | val_loss=0.7406 val_acc=0.9877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.38it/s, acc=1, loss=0.691]\n",
            "Epoch 7/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E7] train_loss=0.6912 train_acc=0.9996 | val_loss=0.6886 val_acc=0.9997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.40it/s, acc=1, loss=0.687]\n",
            "Epoch 8/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E8] train_loss=0.6870 train_acc=1.0000 | val_loss=0.6868 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.33it/s, acc=1, loss=0.686]\n",
            "Epoch 9/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E9] train_loss=0.6865 train_acc=1.0000 | val_loss=0.6866 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.42it/s, acc=1, loss=0.686]\n",
            "Epoch 10/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E10] train_loss=0.6863 train_acc=1.0000 | val_loss=0.6863 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.42it/s, acc=1, loss=0.686]\n",
            "Epoch 11/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E11] train_loss=0.6861 train_acc=1.0000 | val_loss=0.6863 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.41it/s, acc=1, loss=0.686]\n",
            "Epoch 12/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E12] train_loss=0.6860 train_acc=1.0000 | val_loss=0.6862 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.34it/s, acc=1, loss=0.686]\n",
            "Epoch 13/20 [val]: 100%|██████████| 63/63 [00:10<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E13] train_loss=0.6859 train_acc=1.0000 | val_loss=0.6862 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.48it/s, acc=1, loss=0.686]\n",
            "Epoch 14/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E14] train_loss=0.6858 train_acc=1.0000 | val_loss=0.6859 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.50it/s, acc=1, loss=0.686]\n",
            "Epoch 15/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E15] train_loss=0.6857 train_acc=1.0000 | val_loss=0.6859 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.50it/s, acc=1, loss=0.686]\n",
            "Epoch 16/20 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E16] train_loss=0.6857 train_acc=1.0000 | val_loss=0.6859 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20 [train]: 100%|██████████| 354/354 [00:56<00:00,  6.26it/s, acc=1, loss=0.686]\n",
            "Epoch 17/20 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E17] train_loss=0.6857 train_acc=1.0000 | val_loss=0.6859 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.44it/s, acc=1, loss=0.686]\n",
            "Epoch 18/20 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E18] train_loss=0.6857 train_acc=1.0000 | val_loss=0.6858 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20 [train]: 100%|██████████| 354/354 [00:58<00:00,  6.07it/s, acc=1, loss=0.686]\n",
            "Epoch 19/20 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E19] train_loss=0.6856 train_acc=1.0000 | val_loss=0.6858 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.44it/s, acc=1, loss=0.686]\n",
            "Epoch 20/20 [val]: 100%|██████████| 63/63 [00:13<00:00,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E20] train_loss=0.6856 train_acc=1.0000 | val_loss=0.6858 val_acc=1.0000\n",
            "Training complete. Best val_acc: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "DeUonntkV_Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 12\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "BEST_WEIGHTS = \"model.pth\"\n",
        "\n",
        "model = build_model(num_classes=num_classes, pretrained=True).to(DEVICE)\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "def accuracy(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [train]\")\n",
        "    run_loss = 0.0; run_acc = 0.0; n = 0\n",
        "\n",
        "    for x, y in pbar:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        bs = y.size(0)\n",
        "        run_loss += loss.item() * bs\n",
        "        run_acc  += (logits.argmax(1) == y).float().sum().item()\n",
        "        n += bs\n",
        "        pbar.set_postfix(loss=run_loss/n, acc=run_acc/n)\n",
        "\n",
        "    # ---- Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0; val_acc = 0.0; m = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} [val]\"):\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            bs = y.size(0)\n",
        "            val_loss += loss.item() * bs\n",
        "            val_acc  += (logits.argmax(1) == y).float().sum().item()\n",
        "            m += bs\n",
        "    val_loss /= max(1, m)\n",
        "    val_acc  /= max(1, m)\n",
        "\n",
        "    print(f\"[E{epoch}] train_loss={run_loss/n:.4f} train_acc={run_acc/n:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_WEIGHTS)\n",
        "        print(f\"✅ Saved best to {BEST_WEIGHTS} (val_acc={best_val_acc:.4f})\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Training complete. Best val_acc:\", round(best_val_acc, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L1TMpM5WDvG",
        "outputId": "2137ee4c-2d11-48b2-99c1-41da8b0c4324"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1078223694.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
            "Epoch 1/12 [train]:   0%|          | 0/354 [00:00<?, ?it/s]/tmp/ipython-input-1078223694.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
            "Epoch 1/12 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.39it/s, acc=0.952, loss=0.201]\n",
            "Epoch 1/12 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E1] train_loss=0.2006 train_acc=0.9516 | val_loss=0.0055 val_acc=1.0000\n",
            "✅ Saved best to model.pth (val_acc=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/12 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.35it/s, acc=0.998, loss=0.00753]\n",
            "Epoch 2/12 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E2] train_loss=0.0075 train_acc=0.9985 | val_loss=0.0575 val_acc=0.9847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.50it/s, acc=0.996, loss=0.0152]\n",
            "Epoch 3/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E3] train_loss=0.0152 train_acc=0.9964 | val_loss=0.0035 val_acc=0.9992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.51it/s, acc=0.999, loss=0.00732]\n",
            "Epoch 4/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E4] train_loss=0.0073 train_acc=0.9985 | val_loss=0.0095 val_acc=0.9970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/12 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.42it/s, acc=0.999, loss=0.00387]\n",
            "Epoch 5/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E5] train_loss=0.0039 train_acc=0.9990 | val_loss=0.0023 val_acc=0.9990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.53it/s, acc=1, loss=0.000431]\n",
            "Epoch 6/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E6] train_loss=0.0004 train_acc=1.0000 | val_loss=0.0004 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.56it/s, acc=1, loss=0.000164]\n",
            "Epoch 7/12 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E7] train_loss=0.0002 train_acc=1.0000 | val_loss=0.0003 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/12 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.43it/s, acc=1, loss=0.000128]\n",
            "Epoch 8/12 [val]: 100%|██████████| 63/63 [00:08<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E8] train_loss=0.0001 train_acc=1.0000 | val_loss=0.0005 val_acc=0.9997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/12 [train]: 100%|██████████| 354/354 [00:55<00:00,  6.36it/s, acc=1, loss=9.99e-5]\n",
            "Epoch 9/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E9] train_loss=0.0001 train_acc=1.0000 | val_loss=0.0002 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.50it/s, acc=1, loss=8.62e-5]\n",
            "Epoch 10/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E10] train_loss=0.0001 train_acc=1.0000 | val_loss=0.0002 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.50it/s, acc=1, loss=8.45e-5]\n",
            "Epoch 11/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E11] train_loss=0.0001 train_acc=1.0000 | val_loss=0.0002 val_acc=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/12 [train]: 100%|██████████| 354/354 [00:54<00:00,  6.51it/s, acc=1, loss=8.22e-5]\n",
            "Epoch 12/12 [val]: 100%|██████████| 63/63 [00:09<00:00,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E12] train_loss=0.0001 train_acc=1.0000 | val_loss=0.0002 val_acc=1.0000\n",
            "Training complete. Best val_acc: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on official test split"
      ],
      "metadata": {
        "id": "k5Dv7gc_WFbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "TEST_BATCH = 128\n",
        "\n",
        "test_set = datasets.GTSRB(\n",
        "    root=DATA_ROOT, split=\"test\", download=True, transform=get_transforms(train=False)\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_set, batch_size=TEST_BATCH, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "IDX_TO_CLASS = load_label_map(\"label_map.json\")\n",
        "num_classes = len(IDX_TO_CLASS)\n",
        "\n",
        "# Reload best model for test\n",
        "eval_model = build_model(num_classes=num_classes, pretrained=False).to(DEVICE)\n",
        "state = torch.load(BEST_WEIGHTS, map_location=DEVICE)\n",
        "eval_model.load_state_dict(state)\n",
        "eval_model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader, desc=\"Testing\"):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        logits = eval_model(x)\n",
        "        preds = logits.argmax(1)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "y_true = np.concatenate(all_labels)\n",
        "y_pred = np.concatenate(all_preds)\n",
        "acc = (y_true == y_pred).mean()\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "with open(\"eval_report.json\", \"w\") as f:\n",
        "    json.dump(\n",
        "        {\"accuracy\": float(acc), \"per_class\": report, \"confusion_matrix\": cm.tolist()},\n",
        "        f, indent=2\n",
        "    )\n",
        "\n",
        "acc, report[\"macro avg\"][\"f1-score\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijVFP8PVWIqu",
        "outputId": "15652a8e-ebfe-46b7-d562-b298d06b7750"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89.0M/89.0M [00:00<00:00, 232MB/s]\n",
            "100%|██████████| 99.6k/99.6k [00:00<00:00, 2.67MB/s]\n",
            "Testing: 100%|██████████| 99/99 [00:29<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9813935075217736), 0.9770393062079163)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip artifacts for download / Spaces"
      ],
      "metadata": {
        "id": "TuEuVcsaWM9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "artifacts = [\"model.pth\", \"label_map.json\", \"eval_report.json\"]\n",
        "for a in artifacts:\n",
        "    print(a, \"exists?\" , Path(a).exists())\n",
        "\n",
        "with ZipFile(\"traffic_sign_artifacts.zip\", \"w\") as zf:\n",
        "    for a in artifacts:\n",
        "        if Path(a).exists():\n",
        "            zf.write(a)\n",
        "print(\"Wrote traffic_sign_artifacts.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck1V1d-rWPTM",
        "outputId": "5d7a8f32-b2fe-46dd-b478-733dc833addb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.pth exists? True\n",
            "label_map.json exists? True\n",
            "eval_report.json exists? True\n",
            "Wrote traffic_sign_artifacts.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick 12 random TEST images and see top-1 accuracy quickly\n",
        "import random, numpy as np, torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "test_set = datasets.GTSRB(root=\"./data\", split=\"test\", download=True, transform=None) # Remove transform here\n",
        "IDX_TO_CLASS = load_label_map(\"label_map.json\")\n",
        "\n",
        "# reload best model\n",
        "m = build_model(num_classes=len(IDX_TO_CLASS), pretrained=False).to(DEVICE)\n",
        "m.load_state_dict(torch.load(\"model.pth\", map_location=DEVICE)); m.eval()\n",
        "\n",
        "def pred(img: Image.Image):\n",
        "    # Apply transforms here after getting the PIL image\n",
        "    x = get_transforms(train=False)(img).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad(): p = torch.softmax(m(x), -1)[0]\n",
        "    i = int(p.argmax().item()); return i, float(p[i].item())\n",
        "\n",
        "ok = 0\n",
        "for _ in range(12):\n",
        "    j = random.randrange(len(test_set))\n",
        "    img, y = test_set[j] # Access image and target using dataset indexing\n",
        "    i, conf = pred(img)\n",
        "    ok += int(i==y)\n",
        "print(f\"Quick top-1 on 12 random test samples: {ok}/12 correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA3a4-9vWRdX",
        "outputId": "a128d7a8-ff07-45b8-8e46-cee0ec14bad2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quick top-1 on 12 random test samples: 12/12 correct\n"
          ]
        }
      ]
    }
  ]
}